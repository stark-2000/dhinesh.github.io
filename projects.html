<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Dhinesh Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">  <!-- For the fontawesome icons -->
	</head>
	<body class="is-preload">

		<!-- Header -->
		<header id="header">
			<nav>
				<ul>
					<li><a href="index.html">Home</a></li>
					<li><a href="#RAI">Robotics & AI Projects</a></li>
					<li><a href="#ELSW">Electronics & Software Projects</a></li>
					<li><a href="#UR">Undergraduate Research</a></li>
				</ul>
			</nav>
		</header>

		<!-- Sidebar -->
		<section id="sidebar">
			<div class="inner">
				<nav>
					<ul>
						<li><a href="index.html">Home</a></li>						
						<li><a href="about.html">About Myself</a></li>
						<li><a href="resume.html">Resume</a></li>
						<li><a href="professional-exp.html">Professional Experience</a></li>
						<li><a href="patents.html">Patents</a></li>
						<li><a href="skills.html">Skills</a></li>
					</ul>
				</nav>
			</div>
		</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="RAI" class="wrapper">
						<div class="inner">
							
							<!-- --------------------------------------------------------------------------------------------------------- -->
							<h1 class="major">Robotics & AI Projects</h1>


							<!-- ------------------------------------------------------- -->
							<!-- Stepper Motor based Self Balancing Robot with PID control -->
							<section id="SBR">
								<h3>Stepper Motor based Self Balancing Robot with PID control</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/SBR/Robot Pic.png" alt="" /></span>Developed a self-balancing robot using stepper motors and A4988 drivers, driven by an Arduino-based PID balancing algorithm. Created a URDF model and working towards teleoperation from ROS.</p>
								<p>Skills: PID · SOLIDWORKS · ROS · Rviz · Circuit Design</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Stepper Motor Innovation:<br>
								Utilized stepper motors with A4988 drivers, eliminating the need for encoders essential in DC motors, streamlining teleoperation prospects.</p>
								
								<p>✦ Efficient Prototyping:<br>
								Leveraged SOLIDWORKS design and 3D printing for rapid prototyping, expediting development cycles for swift iterations.</p>
								
								<p>✦ Custom Motor Control Function:<br>
								Wrote a custom function for stepper motor control via A4988 drivers, enhancing operational versatility without the use of existing libraries.</p>	
								
								<p>✦ Balancing Algorithm Implementation:<br>
								Employed Arduino's PID library for algorithmic balancing, ensuring stable and accurate self-balancing behavior of the robot.</p>	
								
								<p>✦ Custom PCB Integration:<br>
								Designed a custom PCB integrating A4988 drivers, BMS circuitry, BNO055 IMU, and LiPo battery, optimizing system efficiency and streamlining the functionality.</p>	
								

								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Stepper-Motor-based-Self-Balancing-Robot-with-PID-control.git" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Real-Time Steam Plant Man Hole Cover Detection using Single Shot Detectors - YOLO -->
							<section id="SteamPlantYOLODet">
								<h3>Real-Time Steam Plant Man Hole Cover Detection using Single Shot Detectors - YOLO</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Steam Plant Cover Det - YOLO/Combined Collage.png" alt="" /></span>Implementing YOLOv8, YOLOv5, and YOLOv3 via transfer learning on a local GPU, we aimed to detect steam plant manhole covers. Integration included RGB and FLIR thermal cameras alongside GPS.</p>
								<p>Skills: YOLO · Deep Learning · CUDA · Nvidia Jetson · Arduino · GPS</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Custom Model Training:<br>
								Trained models on a bespoke dataset comprising 2000 images for detecting manhole covers, meticulously evaluating latency and accuracy for optimization.</p>
									
								<p>✦ Real-Time Detection and Alerting:<br>
								Enabled the real-time identification of high-temperature manhole covers with precise GPS coordinates, triggering immediate alerts for facilities management inspection.</p>
								
								<p>✦ Efficient Deployment:<br>
								Deployed Nvidia Jetson Nano with FLIR A50 Thermal camera on a mobile platform, ensuring seamless monitoring and proactive maintenance with location data from Neo-8m GPS.</p>
								<br>
							</section>
							

							<!-- ------------------------------------------------------- -->
							<!-- ARIAC 2023 - Agile Robotics for Industrial Automation -->
							<section id="ARIAC2023">
								<h3>ARIAC 2023 - Agile Robotics for Industrial Automation</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/ARIAC 2023/Simulation Env.png" alt="" /></span>Developed an Industrial Robotics Manufacturing System featuring AGVs, manipulators, and sensors for automated component manufacturing in a ROS2 Gazebo environment. Modeled after the ARIAC 2023 challenge, focusing on agility and autonomy in kitting tasks.</p>
								<p>Skills: ROS · Robotics · Gazebo · Rviz · Software Development · C++ · Python Programming</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Coursework Simulation:<br>
								Developed as part of ENPM663 coursework, mirroring the ARAIC 2023 challenge to assess industrial robot agility.</p>

								<p>✦ ROS2 and Gazebo Frameworks:<br>
								Utilized ROS2, Gazebo, and RViz for system development, integrating UR5 manipulators, AGVs, IR cameras, proximity sensors, and 3D depth cameras.</p>

								<p>✦ Kitting Task Automation:<br>
								Addressed challenges such as fault and inconsistency in parts, emphasizing autonomous completion of kitting tasks within industrial manufacturing.</p>

								<p>✦ Autonomy and Productivity Focus:<br>
								Aligned with ARIAC's objective of enhancing industrial robot autonomy and productivity, minimizing human intervention in complex manufacturing processes.</p>

								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/ARIAC-2023---Agile-Robotics-for-Industrial-Automation" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
									<li><a href="https://www.nist.gov/el/intelligent-systems-division-73500/agile-robotics-industrial-automation-competition/about-ariac" class="button primary"><i class="fa-solid fa-circle-info"></i> About ARIAC</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Autonomous Mobile Robot for Shape-Sorting Application -->
							<section id="809T">
								<h3>Autonomous Mobile Robot for Shape-Sorting Application</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Mobile Robot for Shape Sorting Application/Combined Collage.png" alt="" /></span>Developed an autonomous mobile robot for a demo construction site, proficient in identifying colored shapes and transporting them to designated zones using a 2-DoF gripper.</p>
								<p>Skills: OpenCV · Robotics · Python Programming · Arduino IDE · EasyEDA · Embedded Systems · PID</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Precision Control Implementation:<br>
								Leveraged PID for precise motor synchronization, OpenCV for accurate color detection, and monocular depth estimation for optimal trajectory planning.</p>
								
								<p>✦ Custom Hardware Development:<br>
								Developed a Raspberry Pi-based physical robot from scratch, featuring a custom-built software stack, showcased prominently in a high-stakes grand challenge competition.</p>
								
								<p>✦ Robust Electrical Hardware:<br>
								Engineered hardware using a blend of metal and 3D printed components, along with custom-designed PCBs for seamless interfacing between IMUs, encoders, and the Raspberry Pi.</p>
								
								<p>✦ Integration and Versatility:<br>
								Integrated IMUs via Arduino, programmed in C++, alongside a Python-based detection stack, ensuring robust performance and versatility in operations.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Autonomous-Mobile-Robot-for-Shape-Sorting-Application" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
									<li><a href="https://www.youtube.com/watch?v=pw-fyCgWn7c" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Training & Testing a Neural Network based on YOLOv3 for Custom Object Detection -->
							<section id="YOLOv3CustomObjDet">
								<h3>Training & Testing a Neural Network based on YOLOv3 for Custom Object Detection</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Training & Testing YOLOv3/Screen Shot.png" alt="" /></span>Utilizing transfer learning, we trained neural networks based on YOLOv3 specifically for human detection, leveraging a custom dataset.</p>
								<p>Skills: YOLO · OpenCV · Python Programming · Deep Learning</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Comprehensive Dataset Annotation:<br>
								Utilized data from various open-source repositories, meticulously annotated using LabelImg software to ensure thorough training.</p>
								
								<p>✦ Seamless Model Deployment:<br>
								Successfully deployed trained models on a mobile robot, seamlessly integrating with an IP Cam for real-time human detection in dynamic environments.</p>
								
								<p>✦ Efficient Training Process:<br>
								Training iterations involved 50 epochs with a batch size of 4, executed efficiently on a 3060 laptop GPU, ensuring optimal model performance and accuracy.</p>
								
								
								<ul class="actions">
									<li><a href="https://www.youtube.com/watch?v=1ebHnKMeKpw" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Custom Robotic Arm for Pick & Place Operations using Stereo Vision -->
							<section id="DUM-E">
								<h3>Custom Robotic Arm for Pick & Place Operations using Stereo Vision</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Custom 6DoF Arm/Combined Collage.png" alt="" />
															<video controls style="max-width: 200px; max-height: 250px; margin-left: 200px;"><source src="Media/Images/Projects/Custom 6DoF Arm/Timelapse.mp4" type="video/mp4"></video>
									</span>Engineered a cutting-edge 6-DoF manipulator from the ground up, employing innovative 3D printed designs and assembly, subsequently programmed for essential pick & place functionalities utilizing MoveIt and ROS 2 frameworks.</p>
								
								<p>Skills: ROS · MOVEit · Stereo Vision · SOLIDWORKS · C++ · Arduino IDE · OpenCV · Python Programming · YOLO</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Enhanced Perception Accuracy:<br>
									Utilized Intel RealSense cameras and a custom-built stereo depth estimation library to enhance perception accuracy, crucial for precise manipulation tasks.</p>
									
								<p>✦ Robust Simulation and Testing:<br>
								Constructed a comprehensive URDF model in SOLIDWORKS, rigorously tested in Gazebo before integration with MOVEit for precise programming and validation.</p>
								
								<p>✦ Advanced Motor Control:<br>
								Implemented Arduino Pro Mini as the motor controller and high-torque DC servos, facilitating inter-servo communication via Daisy Chain Architecture or i2c interface, ensuring smooth and synchronized motion.</p>
								
								<p>✦ Performance Evaluation:<br>
								Conducted a comprehensive performance evaluation against the industry-standard UR5e industrial manipulator for identical pick & place tasks, showcasing the capabilities of our design.</p>
								
								<p>✦ Tailored Electronics Integration:<br>
								Developed and fabricated a custom PCB with Arduino and interface circuitry, precisely tailored to the manipulator's CAD model, ensuring optimal functionality and seamless integration.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Custom-Robotic-Arm-for-Pick-Place-Operations-using-Stereo-Vision" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
									<li><a href="https://www.youtube.com/watch?v=uZFN3-d_hQE" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video Part 1</a></li>
									<li><a href="https://www.youtube.com/watch?v=7Xjhg34qU5E" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video Part 2</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Hardware Implementation of Pick & Place Operation using UR5e -->
							<section id="UR5ePickPlace">
								<h3>Hardware Implementation of Pick & Place Operation using UR5e</h3>
								<hr>
									<p><span class="image right"><img src="Media/Images/Projects/UR5e Pick & Place Operation/Picture of Myself with Baxter at RRL.png" alt="" /></span>Developed software stack for Universal Robot's robotic manipulator, specializing in basic pick and place operations. Developed an Inverse Kinematics (IK) solver, tested on Gazebo, and seamlessly deployed on hardware utilizing MoveIt and ROS 2.</p>
									<p>Skills: C++ · ROS · MOVEit · SOLIDWORKS</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Custom IK Solver Development:<br>
								Designed and implemented a custom IK solver, ensuring precise end effector coordination relative to the robot's base, validated through comprehensive testing on Gazebo.</p>
								
								<p>✦ Seamless Integration with MoveIT and ROS 2:<br>
								Integrated with MoveIT and ROS 2, facilitating seamless deployment of the IK solver onto hardware for real-world applications.</p>
								
								<p>✦ Functional Validation:<br>
								Demonstrated functionality by publishing end effector coordinates to the UR5e manipulator in RViz using the C++ Move Group interface, showcasing operational efficacy and reliability.</p>
								
								<p>✦ Real-World Application Testing:<br>
								Successfully demonstrated functionality using Gazebo and a UR5e manipulator from the University of Maryland's Robot Realization Laboratory (RRL).</p>
								
							
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Hardware-Implementation-of-Pick-Place-Operation-using-UR5e" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
									<li><a href="https://www.youtube.com/watch?v=KsT-6AQUsJ8" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Mono-Camera Human Pose Estimation and Tracking using OpenCV -->
							<section id="MonoCamPoseEst">
								<h3>Mono-Camera Human Pose Estimation and Tracking using OpenCV</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Mono-Cam Human Pose Est/Model Output.png" alt="" /></span>Developed an algorithm leveraging OpenCV for human pose estimation, deployed seamlessly on a laptop webcam, providing Cartesian coordinates with depth information in 3D. Implemented robust human tracking across frames with unique ID assignment.</p>
								<p>Skills: C++ · OpenCV · Agile Software Development</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Advanced Algorithm Development:<br>
								Employed OpenCV and C++ with a HOG Detector for precise human detection, following agile methodologies and software development best practices.</p>
								
								<p>✦ Accurate 3D Pose Estimation:<br>
								Achieved 3D pose estimation using monocular depth estimation approximations. Ensured accuracy through rigorous validation against ground truth measurements.</p>
								
								<p>✦ Seamless Integration:<br>
								Seamlessly deployed the algorithm on a laptop webcam, providing real-time 3D Cartesian coordinates with depth information for enhanced understanding.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Mono-Camera-Human-Pose-Estimation-and-Tracking-using-openCV" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
									<li><a href="https://www.youtube.com/watch?v=I7B7vsfU38s" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Smart Kitchen Robot for Automatic Stuffing & Making of Famous Indian Bread Variety -->
							<section id="BakerBot">
								<h3>Smart Kitchen Robot for Automatic Stuffing & Making of Famous Indian Bread Variety</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/BakerBot/Combined Collage.png" alt="" /></span>We have designed and built the world's first fully automated & compact robot that only requires wheat and water to be filled in containers. It can make stuffed parathas, stack them, and store them in hotboxes with smart IoT control. The robot is low cost and would be similar to a microwave oven in both size and cost.</p>
								<p>Skills: Research & Product Development · Creative Problem Solving · Robotics · Sensors · Project Management · Arduino IDE · Hardware Architecture · Lean Startup · Autodesk Fusion 360 · Leadership · OrCAD Capture CIS</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Complete Autonomy:<br>
								BakerBot automates the entire process, from dough preparation to stacking hot, freshly made parathas.</p>
								
								<p>✦ Customizable User Experience:<br>
								Using an Android mobile app, users specify the number of rotis or parathas and desired oil level, ensuring precision in every batch and remote operation.</p>
								
								<p>✦ Mechanical Marvel:<br>
								BakerBot's compact design houses sophisticated mechatronic systems, including precise process tracking, feedback loops, kneading, encrusting, flattening, and baking.</p>
								
								<p>✦ Seamless Integration:<br>
								IoT-based control and mechatronics system powered by an array of sensors and electrical systems, enables effortless operation with just a click from a mobile phone.</p>
								
								<p>✦ Sensor Stack:<br>
								A sensor stack with proximity, IR, and current sensors, coupled with peristaltic pumps, endstops, and reed switches, achieves precise measurements and closed-loop feedback for full automation.</p>
								
							
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Smart-Kitchen-Robot-for-Automatic-Stuffing-Making-of-Famous-Indian-Bread-Variety" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
								</ul>
								<br>
							</section>

						</div>
					</section>


					<section id="ELSW" class="wrapper">
						<div class="inner">

							<!-- --------------------------------------------------------------------------------------------------------- -->
							<h1 class="major">Electronics & Software Projects</h1>
							

							<!-- ------------------------------------------------------- -->
							<!-- Head Gear - Bone Conduction & Accident Prevention Smart Helmet -->
							<section id="HeadSafe">
								<h3>Head Gear - Bone Conduction & Accident Prevention Smart Helmet</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/HeadSafe/CAD_SideView1.png" alt="" /></span>Revolutionizing rider safety with an innovative patented technology, our project integrates advanced driver assistance systems (ADAS) into motorcycle helmets. Real-time alerts and a distraction-free infotainment system leverage HUD and bone conduction technology with i2s for enhanced riding experiences.</p>
								<p>Skills: Research & Product Development · Circuit Design · Embedded Systems · Arduino IDE · C++ · Python Programming · Sensors</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Enhanced Rider Safety:<br>
								Real-time warnings and alerts for accident prevention using handle vibration mitigate distractions, reducing accident risks. Emergency calls made using VoIP server.</p>
								
								<p>✦ Cutting-edge Technology Integration:<br>
								Visor HUD and bone conduction earphone offer seamless audio-visual feedback combined with high-quality i2s stereo audio experience from custom-designed amplifier.</p>
								
								<p>✦ Mechanical Design Validation:<br>
								CAD-modeled helmet design with embedded circuits ensures durability and functionality.</p>
								
								<p>✦ Power-efficient Solution:<br>
								Custom-designed BMP PCB powers Raspberry Pi Zero and onboard sensors, optimizing performance.</p>
								
								<p>✦ ADAS Features:<br>
								Over speed detection, pedestrian crossing detection, and voice-activated Google Assistant embedded and enabled using bone conduction earphone, microphone, and HUD.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Head-Gear--Bone-Conduction-Accident-Prevention-Smart-Helmet" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Black Box Device for Vessels & Fisherman -->
							<section id="AIH">
								<h3>Black Box Device for Vessels & Fisherman</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/AIH/Combined Collage.png" alt="" /></span>Developed a tamper-proof solar-powered black box device for remote ocean vessel monitoring, seamlessly logging and transmitting vital information to a coast guard control room dashboard. Features include tamper alerts, iridium satellite communication, AI-based activity monitoring, and environmental safety measures.</p>
								<p>Skills: Circuit Design · Hardware Architecture · Creative Problem Solving · Embedded Systems · Prototyping · Project Management · Leadership · Design Documents · Sensors</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Tamper-Proof Solar Device:<br>
								Designed a compact, solar-powered black box for ocean vessels, ensuring continuous operation with onboard power backup for up to 7 hours.</p>
								
								<p>✦ Secure Communication:<br>
								Utilized Iridium satellite communication for 24/7 worldwide coverage and data transfer, enabling seamless transmission of essential information to the coast guard control room.</p>
								
								<p>✦ Advanced Data Logging and Monitoring:<br>
								Implemented AI-based activity monitoring and suspicious activity detection on a computer dashboard, analyzing vessel trajectory and pose for potential threats.</p>
								
								<p>✦ Environmental Safety Integration:<br>
								Incorporated environmental safety features such as oil spill detection using UP42 API, enhancing monitoring capabilities for environmental protection.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Black-Box-Device-for-Vessels-Fisherman" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Ferry Smart - All in one Smart Commute System -->
							<section id="Ferry-Smart">
								<h3>Ferry Smart - All in one Smart Commute System</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Ferry-Smart/Combined Collage.png" alt="" /></span>Designed and implemented a hardware-based smart commute solution that bridges the gap between different modes of public transport and acts as a single source for convenient commutation planning with features such as ETA, cost of travel, live tracking, and carbon footprint tracking among others.</p>
								<p>Skills: Arduino IDE · Circuit Design · C++ · Creative Problem Solving · Agile Software Development · Leadership · OrCAD Capture CIS · Design Documents · Embedded Systems</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Integrated Commute Planning:<br>
								Designed a mobile app using Google Maps API to consolidate various public transport modes, enabling convenient route planning and seamless transitions.</p>
								
								<p>✦ GPS-GSM Device Integration:<br>
								Implemented Arduino-based low-cost GPS-GSM devices in public transports, interfacing with the app for accurate ETA and commute planning, ensuring efficient travel management.</p>
								
								<p>✦ Multi-Modal Transport Options:<br>
								Facilitated selection from multiple transport options, with comparison based on cost, ETA, and carbon footprint. Real-time traffic information from Google Maps API enhances ETA accuracy.</p>
								
								<p>✦ Comprehensive Metrics:<br>
								Calculated metrics integrated into the app provide insights into cost, ETA, and carbon footprint, empowering users to make informed commuting decisions for sustainable travel.</p>
								
								
								<ul class="actions">
									<li><a href="https://www.youtube.com/watch?v=TP-4p3WhVFk" class="button primary"><i class="fa-brands fa-youtube" style="color: red;"></i> Demo Video</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Smart Muffler to prevent Noise Induced Hearing Loss  -->
							<section id="NIHL">
								<h3>Smart Muffler to prevent Noise Induced Hearing Loss</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/NIHL - Smart Muffler/Combined Collage.png" alt="" /></span>Designed a MATLAB algorithm using multiple microphones to detect and attenuate sounds above 80 dBA in real-time, enhancing speech clarity. Integrated filters for noise reduction and devised a smart muffler with Raspberry Pi-based data processing to prevent noise-induced hearing loss.</p>
								<p>Skills: MATLAB · Digital Electronics · C++ · Circuit Design</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Real-time Noise Reduction Algorithm:</br>
								Developed MATLAB algorithm to detect and reduce sounds >80 dBA, ensuring a quieter environment.</p>
								
								<p>✦ Speech Enhancement Feature:</br>
								Identified speech signals in noise and amplified them for clarity in noisy settings.</p>
								
								<p>✦ Filter Implementation with MATLAB:</br>
								Utilized MATLAB built-in functions to implement filters, reducing background noise while preserving speech.</p>
								
								<p>✦ Design for Integration into Smart Muffler:</br>
								Integrated noise reduction system into a smart muffler with earphones and Raspberry Pi-based data processing, offering enhanced hearing protection and noise management.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Smart-Muffler-to-prevent-Noise-Induced-Hearing-Loss" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Load Based Safety Regulator -->
							<section id="LBSR">
								<h3>Load Based Safety Regulator</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Load Based Safety Regulator/LBSR-DALLE.png" alt="" /></span>Developed an economical vehicle regualting system, installable as an inbuilt or retrofit feature for public buses. Utilizes piezoelectric disks for footboard load detection and motion sensors to activate the handbrake through ECM when stationary.</p>
								<p>Skills: Arduino IDE · Circuit Design · C++ · Embedded Systems</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Economical Regulating System:</br>
								Designed for vehicles, adaptable as an inbuilt or retrofit solution for public buses, enhancing safety and control.</p>
								
								<p>✦ Piezoelectric Load Detection:</br>
								Utilizes piezoelectric disks to detect footboard load, triggering the handbrake activation when the vehicle is stationary.</p>
								
								<p>✦ Motion Sensing Integration:</br>
								Integrated GPS and IMU as motion sensors, facilitating precise detection of vehicle state and enabling control over the braking system or throttle through the ECM.</p>
								
								<p>✦ Visual and Auditory Indication:</br>
								Activates indication LED and buzzer on the vehicle dashboard until the footboard load is removed, providing clear signals to the driver and passengers.</p>
								<br>
							</section>
							

							<!-- ------------------------------------------------------- -->
							<!-- Density Based Traffic Lighting System -->
							<section id="DBTLS">
								<h3>Density Based Traffic Lighting System</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/Density Based Traffic Lighting System/DBTLS-DALLE.png" alt="" /></span>Created a smart traffic lighting prototype, dynamically adjusting signal timings at intersections based on traffic density. Utilizes IR array sensors embedded in roads for vehicle detection, enabling algorithm-driven signal adjustments.</p>
								<p>Skills: Arduino IDE · C++ · Sensors</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Dynamic Signal Timing:</br>
								Adapts signal timings at intersections based on real-time traffic density, enhancing traffic flow and reducing congestion.</p>
								
								<p>✦ IR Array Sensors:</br>
								Embedded in roads for precise vehicle detection, providing feedback to the smart algorithm for timely signal adjustments.</p>
								
								<p>✦ Algorithm-Driven Control:</br>
								Utilizes a smart algorithm to analyze sensor data and dynamically alter signal timings, optimizing traffic management.</p>
								
								<p>✦ Prototype Development:</br>
								Implemented with IR array sensors and Arduino microcontroller, showcasing feasibility and effectiveness for real-world deployment.</p>
								
								
								<ul class="actions">
									<li><a href="https://github.com/stark-2000/Density-Based-Traffic-Lighting-System" class="button primary"><i class="fa-brands fa-github"></i> GITHUB</a></li>
								</ul>
								<br>
							</section>


							<!-- ------------------------------------------------------- -->
							<!-- Wireless Health Monitoring System -->
							<section id="WHMS">
								<h3>Wireless Health Monitoring System</h3>
								<hr>
								<p><span class="image right"><img src="Media/Images/Projects/WHMS/Combined Collage.png" alt="" /></span>Developed a prototype for simplified doctor monitoring, enabling 24/7 wireless tracking of vital parameters (ECG, pulse rate, breath rate, temperature), alongside motion sensor-based seizure detection for post-operative patients.</p>
								<p>Skills: Arduino IDE · Sensors · C++ · Hardware Architecture · Visual Studio</p>
								
								<h3>Key Achievements</h3>

								<p>✦ Seamless Vital Parameter Monitoring:</br>
								Enabled continuous wireless tracking of vital parameters such as ECG, pulse rate, breath rate, and temperature for enhanced patient care.</p>
									
								<p>✦ Post-Operative Seizure Detection:</br>
								Implemented IR-based motion sensor seizure detection to promptly alert medical staff, ensuring timely intervention and patient safety.</p>
								
								<p>✦ Efficient Communication and Data Collection:</br>
								Utilized Zigbee mesh networking for seamless communication with doctors and other devices within the hospital, while Arduino facilitated sensor interfacing and data acquisition.</p>
								
								<p>✦ Intuitive Doctor Monitoring Dashboard:</br>
								Developed a Visual Studio-based Windows dashboard for doctors to monitor patient vital signs efficiently, providing real-time insights for informed decision-making.</p>
								<br>
							</section>
							
						</div>
					</section>

					<section id="UR" class="wrapper">
						<div class="inner">		
							
							<!-- --------------------------------------------------------------------------------------------------------- -->
							<h1 class="major">Undergraduate Research</h1>


							<!-- ------------------------------------------------------- -->
							<!-- Sustainable Energy using Cow's Methanogenesis -->
							<h3>Sustainable Energy using Cow's Methanogenesis</h3>
							<hr>
							<p><span class="image right"><img src="Media/Images/Projects/Undergraduate Research/Combined Collage.png" alt="" /></span>Proposed a revolutionary device capturing methane emissions from cow burps, storing it in an inflatable pouch for cooking or fueling bio-based vehicles.</p>
							<p>Skills: Hardware Architecture · Circuit Design · Creative Problem Solving · Sensors · Research & Product Development · EasyEDA</p>
							
							<h3>Key Achievements</h3>

							<p>✦ Innovative Methane Capture System:</br>
							Developed a device to capture and store methane emissions from cow burps in an inflatable pouch, offering a new sustainable energy source for cooking or biofuel and mitigating climate change.</p>
							
							<p>✦ Smart MANET Protocol Integration:</br>
							Deployed Smart MANET Protocol for 24/7 monitoring of cow burping patterns and pouch fuel levels in remote areas without internet or Wi-Fi, ensuring efficient operation.</p>
							
							<p>✦ Automatic Sensing and Management:</br>
							Incorporated automatic sensing of cow burps, with the device filtering and storing methane gas in the pouch. Alerts notify when the pouch is full, requiring replacement or utilization.</p>
							<br>
							
						</div>
					</section>

			</div>

		<!-- Footer -->
		<footer id="footer" class="wrapper style1-alt">
			<div class="inner">
				<ul class="menu">
					<li> PORTFOLIO. DESIGN BY: DHINESH RAJASEKARAN</li>
				</ul>
			</div>
		</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
